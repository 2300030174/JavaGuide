---
title: Summary of Common Kafka Issues
category: High Performance
tag:
  - Message Queue
---

## Kafka Basics

### What is Kafka? What are its main application scenarios?

Kafka is a distributed streaming processing platform. What does that mean exactly?

A streaming platform has three key functions:

1. **Message Queue**: It publishes and subscribes to message streams, which is similar to a message queue, and this is also the reason Kafka is classified as a message queue.
1. **Fault-tolerant Persistent Storage for Recorded Message Streams**: Kafka persists messages to disk, effectively avoiding the risk of message loss.
1. **Streaming Processing Platform**: It processes messages at the time of publishing, and Kafka provides a complete library for streaming processing.

Kafka primarily has two major application scenarios:

1. **Message Queue**: It establishes real-time streaming data pipelines to reliably acquire data between systems or applications.
1. **Data Processing**: It builds real-time streaming data processing programs to transform or process data streams.

### What are the advantages of Kafka compared to other message queues?

When we talk about Kafka now, we already assume it is a very excellent message queue. We often compare it with RocketMQ and RabbitMQ. I think Kafka's main advantages over other message queues are as follows:

1. **Extreme Performance**: Developed in Scala and Java, heavily utilizing batch processing and asynchronous principles in its design, it can process tens of millions of messages per second at its peak.
1. **Unmatched Ecosystem Compatibility**: The compatibility of Kafka with surrounding ecosystems is the best without rival, especially in the fields of big data and stream computing.

In fact, in the early days, Kafka was not a qualified message queue; early Kafka was like a ragged child in the message queue domain, with incomplete functions and some minor issues such as message loss and lack of message reliability guarantees. Of course, this also relates to LinkedIn's initial development of Kafka for processing massive logs. Haha, it wasn't intended to serve as a message queue initially; who knew it would inadvertently occupy a place in the message queue domain later.

With subsequent development, these shortcomings were gradually fixed and improved in Kafka. Thus, the statement that **Kafka is unreliable as a message queue is outdated!**

### Do you understand the queue model? Do you know Kafka's message model?

> Sidebar: Early JMS and AMQP are standards developed by authoritative organizations in the message service field. I introduced this in my article [“Message Queue is Actually Simple”](https://github.com/Snailclimb/JavaGuide#%E6%95%B0%E6%8D%AE%E9%80%9A%E4%BF%A1%E4%B8%AD%E9%97%B4%E4%BB%B6) on [JavaGuide](https://github.com/Snailclimb/JavaGuide). However, these standards have not kept up with the evolution speed of message queues, and they are now effectively obsolete. Therefore, it's possible that different message queues have their own unique message models.

#### Queue Model: Early Message Model

![Queue Model](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/%E9%98%9F%E5%88%97%E6%A8%A1%E5%9E%8B23.png)

**Using a Queue as the medium for message communication satisfies the producer-consumer model; each message can only be used by one consumer, and unconsumed messages are retained in the queue until consumed or timed out.** For example: If we have a producer sending 100 messages, typically two consumers will consume in order, each taking half (one for you and one for me).

**Issues with the Queue Model:**

Suppose we have a situation where we need to distribute messages generated by producers to multiple consumers, and each consumer should receive the complete message content.

In this case, the queue model is not well-suited to solve the issue. Many nitpickers might say: we can create a separate queue for each consumer and let the producer send multiple copies. This is a very foolish approach; not only is it a waste of resources, but it also defeats the purpose of using a message queue.

#### Publish-Subscribe Model: Kafka's Message Model

The publish-subscribe model mainly addresses the issues present in the queue model.

![Publish-Subscribe Model](https://oss.javaguide.cn/java-guide-blog/%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%9E%8B.png)

The publish-subscribe model (Pub-Sub) uses **topics** as the medium for message communication, similar to a **broadcast mode**; a publisher publishes a message, and that message is transmitted to all subscribers via the topic. **Users who subscribe after the message is broadcast will not receive the message.**

**In the publish-subscribe model, if there is only one subscriber, it is essentially the same as the queue model. Thus, the publish-subscribe model can functionally accommodate the queue model.**

**Kafka adopts the publish-subscribe model.**

> **RocketMQ's message model is fundamentally the same as Kafka's. The only difference is that Kafka does not have the concept of a queue, corresponding instead to Partition.**

## Core Concepts of Kafka

### What are Producer, Consumer, Broker, Topic, and Partition?

Kafka sends messages produced by producers to **Topics**, and consumers that need these messages can subscribe to these **Topics**, as shown in the diagram below:

![](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue20210507200944439.png)

The diagram above introduces several important concepts in Kafka:

1. **Producer**: The party generating messages.
1. **Consumer**: The party consuming messages.
1. **Broker**: Can be viewed as an independent Kafka instance. Multiple Kafka Brokers form a Kafka Cluster.

At the same time, you should also notice that each Broker contains the important concepts of Topic and Partition:

- **Topic**: Producers send messages to specific topics; Consumers consume messages by subscribing to specific Topics.
- **Partition**: A Partition is part of a Topic. A Topic can have multiple Partitions, and Partitions under the same Topic can be distributed across different Brokers, indicating that a Topic can span multiple Brokers, just like the diagram above shows.

> Key Point: **Partitions in Kafka can actually correspond to queues in message queues. This should make it easier to understand, right?**

### Do you understand Kafka's replica mechanism? What benefits does it bring?

Another important aspect is Kafka's introduction of a replica mechanism for partitions. Within a partition, there are multiple replicas, among which one is designated as the leader, while the others are called followers. Messages we send are sent to the leader replica, and only then can the follower replicas pull messages from the leader to sync.

> Producers and consumers only interact with the leader replica. You can think of the other replicas as mere copies of the leader. Their existence is only to ensure the security of message storage. When a leader replica fails, one follower is elected as the new leader, but followers that do not meet the sync criteria with the leader will not participate in the election.

**What are the benefits of Kafka's partition and replica mechanism?**

1. Kafka improves concurrency capability (load balancing) by specifying multiple Partitions for a particular Topic, each distributed across different Brokers.
1. Partitions can specify corresponding replica numbers, which greatly enhances message storage security and disaster recovery capabilities, although it also increases the required storage space.

## Zookeeper and Kafka

### What is Zookeeper's role in Kafka?

> To understand Zookeeper's role in Kafka, you must set up a Kafka environment and then explore Zookeeper to see what folders are related to Kafka and what information each node saves. Don't just read without practice, as you'll eventually forget what you've learned! This part of the content references and draws from this article: <https://www.jianshu.com/p/a036405f989c>.

The image below shows my local Zookeeper successfully linked to my local Kafka (the folder structure below was implemented using the idea plugin Zookeeper tool).

<img src="https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/zookeeper-kafka.jpg" style="zoom:50%;" />

ZooKeeper mainly provides metadata management functions for Kafka.

From the image, we can see that Zookeeper primarily does the following for Kafka:

1. **Broker Registration**: There is a dedicated node in Zookeeper for recording the Broker server list. Each Broker will register itself upon starting, creating its own node under `/brokers/ids`. Each Broker will record its IP address, port, and other information in that node.
1. **Topic Registration**: In Kafka, messages from the same Topic are divided into multiple partitions and distributed across multiple Brokers. **The information about these partitions and their corresponding Brokers is also maintained by Zookeeper.** For example, if I create a topic named my-topic with two partitions, corresponding folders would be created in Zookeeper: `/brokers/topics/my-topic/Partitions/0`, `/brokers/topics/my-topic/Partitions/1`.
1. **Load Balancing**: As mentioned earlier, Kafka can provide better concurrency capability by specifying multiple Partitions for a particular Topic, with each Partition distributed across different Brokers. For different Partitions of the same Topic, Kafka will strive to distribute these Partitions across different Broker servers. When a producer generates a message, it will also attempt to deliver it to different Brokers’ Partitions. When Consumers consume, Zookeeper can achieve dynamic load balancing according to the current number of Partitions and Consumers.
1. ……

### Can Kafka be used without introducing Zookeeper?

Before Kafka 2.8, Kafka was heavily criticized for its heavy dependency on Zookeeper. After Kafka 2.8, KRaft mode based on the Raft protocol was introduced, eliminating the need for Zookeeper, significantly simplifying Kafka's architecture and allowing you to use Kafka in a lightweight manner.

However, a reminder: **If you want to use KRaft mode, it is suggested to choose a higher version of Kafka, as this feature is still under continuous improvement and optimization. Kafka version 3.3.1 is the first version to mark the KRaft (Kafka Raft) consensus protocol as production-ready.**

![](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/kafka3.3.1-kraft-production-ready.png)

## Kafka Consumption Order, Message Loss and Duplicate Consumption

### How does Kafka guarantee the order of message consumption?

In the process of using message queues, we often have business scenarios that require strict guarantees on the order of message consumption. For example, if we send two messages simultaneously, the corresponding operations in the database are:

1. Change the user's membership level.
1. Calculate the order price based on the membership level.

If the order in which these two messages are consumed is different, the final result could be completely different.

We know that Kafka's Partitions are the actual storage locations for messages, where the messages we send are placed. Our Partitions exist within the concept of Topics, and we can specify multiple Partitions for a specific Topic.

![](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/KafkaTopicPartionsLayout.png)

Each time a message is added to a Partition, it is appended sequentially, as shown in the image above. **Kafka can only guarantee the order of messages within a Partition.**

> Messages are assigned a specific offset when added to a Partition. Kafka uses offsets to ensure the order of messages within the partition.

Thus, there is a simple way to ensure the order of message consumption: **1 Topic corresponds to 1 Partition.** Of course, this solves the problem but violates Kafka's original design intent.

When sending a message in Kafka, you can specify four parameters: topic, partition, key, and data. If you specify the Partition when sending the message, all messages will be sent to that specified Partition. Moreover, messages with the same key can only be sent to the same Partition, which we can achieve by using table/object IDs as keys.

In summary, there are two methods to ensure the order of message consumption in Kafka:

1. One Topic corresponds to one Partition.
1. (Recommended) Specify key/Partition when sending messages.

Of course, there are additional methods, but the two mentioned above are quite straightforward.

### How does Kafka guarantee messages are not lost?

#### Producer Missing Messages

When a Producer calls the `send` method to send a message, the message may not be delivered due to network issues.

Thus, we cannot assume that a message was successfully sent just because we called the `send` method. To confirm that the message was sent successfully, we have to determine the result of the message sending. It's worth noting that the Kafka producer uses the `send` method to send messages, which is actually an asynchronous operation. We can obtain the result of the call through the `get()` method, but this turns it into a synchronous operation, as shown in the sample code below:

> **For detailed code, please refer to my article: [Kafka Series Part 3! Learn how to use Kafka as a message queue in a Spring Boot program in 10 minutes?](https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247486269&idx=2&sn=ec00417ad641dd8c3d145d74cafa09ce&chksm=cea244f6f9d5cde0c8eb233fcc4cf82e11acd06446719a7af55230649863a3ddd95f78d111de&token=1633957262&lang=zh_CN#rd)**

```java
SendResult<String, Object> sendResult = kafkaTemplate.send(topic, o).get();
if (sendResult.getRecordMetadata() != null) {
  logger.info("Producer successfully sent message to " + sendResult.getProducerRecord().topic() + "-> " + sendResult.getProducerRecord().value().toString());
}
```

However, this is generally not recommended! A better approach would be to use a callback function, as shown in the sample code below:

```java
ListenableFuture<SendResult<String, Object>> future = kafkaTemplate.send(topic, o);
future.addCallback(result -> logger.info("Producer successfully sent message to topic:{} partition:{} message", result.getRecordMetadata().topic(), result.getRecordMetadata().partition()),
                ex -> logger.error("Producer failed to send message, reason: {}", ex.getMessage()));
```

If message sending fails, we can check the reasons for failure and resend the message!

Additionally, it's recommended to set a reasonable value for the Producer's 'retries' (retry count), generally set to 3. However, to ensure no message loss, a somewhat larger value is usually set. After this is configured, if network issues occur, the message sending can be automatically retried to avoid loss. It is also advisable to set a retry interval; if the interval is too short, the effect of retrying will be diminished since multiple retries could happen within a short duration due to a single network fluctuation.

#### Consumer Missing Messages

When we add messages to a Partition, each message receives a specific offset. The offset indicates the current position in the Partition that the Consumer has reached. Kafka uses offsets to ensure the order of messages within the partition.

![kafka offset](https://oss.javaguide.cn/github/javaguide/high-performance/message-queue/kafka-offset.jpg)

Once a Consumer retrieves a message from a Partition, the offset is automatically committed. However, automatic committing introduces a problem: suppose when the Consumer just grabs this message to consume, it suddenly crashes. The message has not actually been consumed, but the offset has been automatically committed.

**A more straightforward solution is to manually turn off automatic offset committing and manually commit the offset only after truly consuming the message.** However, careful observers will note that this could lead to the problem of re-consuming the message. For instance, if you consume a message successfully but crash before committing the offset, that message could theoretically be consumed twice.

#### Kafka Losing Messages

We know that Kafka introduces a replica mechanism for partitions. Within a partition, there are multiple replicas, one designated as the leader and the others as followers. Messages sent to Kafka are delivered to the leader replica first, then the follower replicas pull messages from the leader to sync. Producers and consumers only interact with the leader. You can think of other replicas as mere copies of the leader, existing solely to guarantee message storage security.

**Consider a scenario where the broker hosting the leader replica suddenly crashes. In this case, a new leader has to be elected from among the follower replicas. However, if the leader has data that the follower has not yet synced, it could result in message loss.**

**Setting acks = all**

The remedy for this is to set **acks = all**. The acks parameter is very important for Kafka producers.

The default value of acks is 1, which means our message is deemed successfully sent once it is received by the leader replica. By configuring **acks = all**, it indicates that the producer will only receive a response from the server when all replicas in the ISR (in-sync replica) list have received the message. This mode is the highest level of reliability and ensures that more than one Broker has received the message, although it incurs higher latency.

**Setting replication.factor >= 3**

To ensure that the leader replica has follower replicas that can sync messages, we generally set **replication.factor >= 3** for topics. This ensures that each partition has at least three replicas. Although this introduces data redundancy, it provides increased data security.

**Setting min.insync.replicas > 1**

In typical cases, we also need to set **min.insync.replicas > 1**. This configuration means that a message must be written to at least two replicas to be considered successfully sent. The default value of **min.insync.replicas** is 1, and in practice, this default value should be avoided.

However, to ensure high availability of the entire Kafka service, you must ensure that **replication.factor > min.insync.replicas**. Why? If the two values are equal, as soon as one replica fails, the entire partition becomes non-functional, which clearly violates the principle of high availability! It is generally recommended to set **replication.factor = min.insync.replicas + 1**.

**Setting unclean.leader.election.enable = false**

> **Starting from Kafka version 0.11.0.0, the default value of the unclean.leader.election.enable parameter changed from true to false.**

As mentioned, messages are sent to the leader replica first, which then allows the followers to sync messages. The synchronization state among various follower replicas can differ. When we configure **unclean.leader.election.enable = false**, if the leader replica fails, it will not select a leader from replicas that do not meet the synchronization criteria with the leader, thus reducing the likelihood of message loss.

### How does Kafka ensure messages are not consumed multiple times?

**Causes of duplicate message consumption in Kafka:**

- The data that has already been consumed on the server side was not successfully committed (the root cause).
- On the Kafka side, service processing time is too long or network connectivity issues can cause Kafka to think the service is in a pseudo-dead state, triggering a partition rebalance.

**Solutions:**

- Implement idempotent checks in the message consumption service, such as using Redis's set or MySQL's primary key, which inherently provides idempotence. This method is the most effective.
- Configure the **`enable.auto.commit`** parameter to false to disable automatic commits; developers manually commit the offset in their code. However, this raises the question: **When is it appropriate to commit the offset?**
  - Commit after processing the message: This still carries the risk of duplicate consumption, similar to automatic committing.
  - Commit immediately after pulling the message: This incurs a risk of message loss. Scenarios allowing message delays often adopt this approach, followed by timed tasks performed during off-peak hours (e.g., midnight) to ensure data integrity.

## Kafka Retry Mechanism

In the discussion about how Kafka ensures messages are not lost, we touched on Kafka's retry mechanism. Since this part is quite important, we'll elaborate on it here.

There are many articles online about Spring Kafka's default retry mechanism, but most are outdated and do not reflect actual running results. Below is a reorganization based on the [spring-kafka-2.9.3](https://mvnrepository.com/artifact/org.springframework.kafka/spring-kafka/2.9.3) source code.

### What happens if consumption fails?

During the consumption process, if one message fails to process, will it block the consumption of subsequent queued messages? Wouldn't that stall the business?

Producer code:

```Java
 for (int i = 0; i < 10; i++) {
   kafkaTemplate.send(KafkaConst.TEST_TOPIC, String.valueOf(i))
 }
```

Consumer code:

```Java
   @KafkaListener(topics = {KafkaConst.TEST_TOPIC}, groupId = "apple")
   private void customer(String message) throws InterruptedException {
       log.info("kafka customer:{}", message);
       Integer n = Integer.parseInt(message);
       if (n % 5 == 0) {
           throw new RuntimeException();
       }
   }
```

Under the default configuration, if a consumption exception occurs, it will attempt retries. After multiple retries, it will skip the current message and continue processing the subsequent messages, thus not blocking on the current message. The log below shows that `test-0@95` is skipped after multiple retries.

```Java
2023-08-10 12:03:32.918 DEBUG 9700 --- [ntainer#0-0-C-1] o.s.kafka.listener.DefaultErrorHandler   : Skipping seek of: test-0@95
2023-08-10 12:03:32.918 TRACE 9700 --- [ntainer#0-0-C-1] o.s.kafka.listener.DefaultErrorHandler   : Seeking: test-0 to: 96
2023-08-10 12:03:32.918 INFO 9700 --- [ntainer#0-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-apple-1, groupId=apple] Seeking to offset 96 for partition test-0
```

Therefore, even if one message fails to process, the Kafka consumer can still continue consuming subsequent messages, ensuring normal business operation.

### How many retries are there by default?

Under the default configuration, when an exception occurs during consumption, retries will take place. So how many retries are there, and is there a time interval between retries?

Examining the `FailedRecordTracker` class, there is a `recovered` function that returns a Boolean value to determine if a retry should occur. Here’s the logic for determining whether to attempt a retry within this function:

```java
@Override
public boolean recovered(ConsumerRecord << ? , ? > record, Exception exception,
    @Nullable MessageListenerContainer container,
    @Nullable Consumer << ? , ? > consumer) throws InterruptedException {

    if (this.noRetries) {
        // Not supporting retries
        attemptRecovery(record, exception, null, consumer);
        return true;
    }
    // Retrieve the collection of already failed consumption records
    Map < TopicPartition, FailedRecord > map = this.failures.get();
    if (map == null) {
        this.failures.set(new HashMap < > ());
        map = this.failures.get();
    }
    // Get the Topic and Partition where the consumption record is located
    TopicPartition topicPartition = new TopicPartition(record.topic(), record.partition());
    FailedRecord failedRecord = getFailedRecordInstance(record, exception, map, topicPartition);
    // Notify registered retry listeners of message delivery failure
    this.retryListeners.forEach(rl -> rl.failedDelivery(record, exception, failedRecord.getDeliveryAttempts().get()));
    // Get the next retry interval
    long nextBackOff = failedRecord.getBackOffExecution().nextBackOff();
    if (nextBackOff != BackOffExecution.STOP) {
        this.backOffHandler.onNextBackOff(container, exception, nextBackOff);
        return false;
    } else {
        attemptRecovery(record, exception, topicPartition, consumer);
        map.remove(topicPartition);
        if (map.isEmpty()) {
            this.failures.remove();
        }
        return true;
    }
}
```

Within this code, `BackOffExecution.STOP` is defined as -1.

```java
@FunctionalInterface
public interface BackOffExecution {

    long STOP = -1;
    long nextBackOff();

}
```

The value of `nextBackOff` is determined by calling the `nextBackOff()` function of the `BackOff` class. If the number of executions exceeds the maximum attempts, it returns `STOP`, meaning it will only stop retries after reaching the maximum number of attempts.

```java
public long nextBackOff() {
  this.currentAttempts++;
  if (this.currentAttempts <= getMaxAttempts()) {
    return getInterval();
  }
  else {
    return STOP;
  }
}
```

So, what is the value of `getMaxAttempts`? Returning to the beginning, when an error occurs, it goes into `DefaultErrorHandler`. The default constructor of `DefaultErrorHandler` is:

```Java
public DefaultErrorHandler() {
  this(null, SeekUtils.DEFAULT_BACK_OFF);
}
```

`SeekUtils.DEFAULT_BACK_OFF` is defined as:

```Java
public static final int DEFAULT_MAX_FAILURES = 10;

public static final FixedBackOff DEFAULT_BACK_OFF = new FixedBackOff(0, DEFAULT_MAX_FAILURES - 1);
```

The value of `DEFAULT_MAX_FAILURES` is 10; therefore, `currentAttempts` ranges from 0 to 9, making a total of 10 attempts, each with an interval of 0.

In summary, Kafka consumers, under the default configuration, will attempt a maximum of 10 retries, with each retry having an interval of 0, meaning they will retry immediately. If, after 10 attempts, the message still cannot be consumed successfully, it will not be retried further, and the message will be regarded as failed consumption.

### How to customize retry counts and time intervals?

As indicated in the above code, the default error handler's retry count and time interval are controlled by the `FixedBackOff`, which is initialized by the `DefaultErrorHandler` by default. Thus, we can customize the retry count and time interval simply by passing a custom `FixedBackOff` when initializing the `DefaultErrorHandler`. To implement this, you can create a new `KafkaListenerContainerFactory`, invoking `setCommonErrorHandler` to set up a new custom error handler.

```Java
@Bean
public KafkaListenerContainerFactory kafkaListenerContainerFactory(ConsumerFactory<String, String> consumerFactory) {
    ConcurrentKafkaListenerContainerFactory factory = new ConcurrentKafkaListenerContainerFactory();
    // Custom retry time interval and counts
    FixedBackOff fixedBackOff = new FixedBackOff(1000, 5);
    factory.setCommonErrorHandler(new DefaultErrorHandler(fixedBackOff));
    factory.setConsumerFactory(consumerFactory);
    return factory;
}
```

### How to alert when retries fail?

To handle custom logic for when retries fail, you need to manually implement it. Below is a simple example where the `handleRemaining` function of the `DefaultErrorHandler` is overridden to include custom alerting operations.

```Java
@Slf4j
public class DelErrorHandler extends DefaultErrorHandler {

    public DelErrorHandler(FixedBackOff backOff) {
        super(null, backOff);
    }

    @Override
    public void handleRemaining(Exception thrownException, List<ConsumerRecord<?, ?>> records, Consumer<?, ?> consumer, MessageListenerContainer container) {
        super.handleRemaining(thrownException, records, consumer, container);
        log.info("Retry failed multiple times");
        // Custom operations
    }
}
```

The `DefaultErrorHandler` is merely a default error handler; Spring Kafka also provides a `CommonErrorHandler` interface. You can implement `CommonErrorHandler` manually to achieve more custom operations, allowing for a high level of flexibility; for instance, to implement different retry logic and business logic based on various error types.

### How to process data again after retry failures?

Once the maximum retry count has been reached, data will simply be skipped, and processing will continue. After the code issues are fixed, how can we re-consume the data that failed to process?

**Dead Letter Queue (DLQ)** is a special queue in message middleware for handling messages that cannot be correctly processed by consumers. This is usually due to issues like incorrect message formats, processing failures, or consumption timeouts leading to messages being "discarded" or "dead." When a message enters the queue, consumers will attempt to process it. If processing fails, or it cannot be successfully processed after exceeding the retry count, the message can be sent to a dead letter queue instead of being permanently discarded. In the dead letter queue, these problematic messages can be further analyzed and processed to identify issues, correct errors, and take appropriate action.

`@RetryableTopic` is an annotation in Spring Kafka used to configure a specific Topic to support message retries. It is recommended to leverage this annotation for retries.

```Java
// Retry 5 times, with a 100-millisecond interval and a maximum of 1 second
@RetryableTopic(
        attempts = "5",
        backoff = @Backoff(delay = 100, maxDelay = 1000)
)
@KafkaListener(topics = {KafkaConst.TEST_TOPIC}, groupId = "apple")
private void customer(String message) {
    log.info("kafka customer:{}", message);
    Integer n = Integer.parseInt(message);
    if (n % 5 == 0) {
        throw new RuntimeException();
    }
    System.out.println(n);
}
```

When the maximum retry count is reached, if the message is still not processed successfully, it'll be sent to the corresponding dead letter queue. Handling of dead letter queues can be done through `@DltHandler` or re-consuming with `@KafkaListener`.

## References

- Kafka Official Documentation: <https://kafka.apache.org/documentation/>
- Geek Time - Section 11 of “Kafka Core Technologies and Practice”: How to configure for no message loss?
